## About me

My name is Matt Warner, I recently completed my Master's in Sound and Music Computing at Queen Mary's University of London (within the school of electrical enginnering & computer science) - achieving distinction (70%+). Previous to that I completed an MSci degree in Physics at the same university. My free time mainly consists of listening to and creating my own music in Abeleton.

## Master's dissertation

Titled 'The Determinant Interface Model for Music Cognition – Peeling Back the Cognitive Layers of Our Everyday Music Listening,' my project (where I achieved a mark of 80%) consisted of first hypothesizing my own cognitive model through reviewing the relevant literature (neurological, cognitive & behavioral studies), testing that model by using 25 self-gathered participants, and analyzing the self-collected data through code.

My research found that when hearing short melodies (10s), we judge their enjoyability purely based on how much "musical sense" they make to us. However, by using different timbral sounds (like switching instruments or changing how the instruments sound "texturally"), it allows the listener to enjoy otherwise more complex, dissonant-sounding melodies. On top of this, the leading factor for music enjoyability was artist recognition over the actual musical piece itself, i.e., participants based song enjoyability more on the musical artist themselves rather than the actual music, by quite a significant margin.

['The Determinant Interface Model for Music Cognition – Peeling Back the Cognitive Layers of Our Everyday Music Listening'.pdf](https://github.com/warner-d-m/warner-d-m.github.io/files/13631604/The.Determinant.Interface.Model.for.Music.Cognition.Peeling.Back.the.Cognitive.Layers.of.Our.Everyday.Music.Listening.pdf)

## Other project examples

Adapting a generative adversarial network (akin to DALL·E or Midjourney) for royality sample generation for music production via 2D spectrograms generation; [Creative Computing final report.pdf](https://github.com/warner-d-m/warner-d-m.github.io/files/13631660/Creative.Computing.final.report.pdf)

Implementing, training, and comparing two deep learning (AI) systems for audio, performing two tasks: separation and classification; [Report.pdf](https://github.com/warner-d-m/warner-d-m.github.io/files/13632241/Report.pdf)

Sampling based looper digital instrument using Bela board; [Sampling based looper digital.pdf](https://github.com/warner-d-m/warner-d-m.github.io/files/13632289/Sampling.based.looper.digital.pdf)
